{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a href=\"https://colab.research.google.com/github/pix2712/10-Fruit/blob/main/10_Fruits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","metadata":{"id":"view-in-github"}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.optimizers import RMSprop\nimport matplotlib.pyplot as plt\nimport tensorflow as tf \nimport numpy as np\nimport os\n","metadata":{"id":"xC82Q5o6SEHF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from google.colab import drive\ndrive.mount('/content/gdrive')","metadata":{"id":"popyjUgLSPex","outputId":"7277d843-c98d-4368-bab1-62efa325e356"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = ImageDataGenerator(rescale = 1./255)\nvalidation = ImageDataGenerator(rescale=1/255)","metadata":{"id":"KKwYrnk8SS-4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = train.flow_from_directory('/content/gdrive/MyDrive/Exam/10 Fruits/Train',target_size=(150,150),batch_size=3,class_mode='categorical')\nvalidation_dataset = train.flow_from_directory('/content/gdrive/MyDrive/Exam/10 Fruits/Validation',target_size=(150,150),batch_size=3,class_mode='categorical')","metadata":{"id":"UNvGDdFaSYW0","outputId":"424dd2b6-efcf-4704-e721-c2301aab5601"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset.class_indices","metadata":{"id":"jPzH_NfGSkyP","outputId":"5c908973-12b7-40e8-db39-f75cb9fa8123"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.layers import Dense, Dropout, Flatten\nfrom keras.models import Sequential, load_model\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom keras.utils import np_utils\nfrom tensorflow.keras.optimizers import SGD\n\nmodel = Sequential()\nmodel.add(Conv2D(32,(3,3),activation='relu',kernel_initializer='he_uniform',padding ='same',input_shape=(150,150,3)))\nmodel.add(MaxPooling2D((2,2)))\n\n\nmodel.add(Conv2D(32,(3,3),activation='relu',kernel_initializer='he_uniform',padding ='same'))\nmodel.add(MaxPooling2D((2,2)))\n\nmodel.add(Conv2D(64,(3,3),activation='relu',kernel_initializer='he_uniform',padding ='same'))\nmodel.add(MaxPooling2D((2,2)))\n\nmodel.add(Conv2D(64,(3,3),activation='relu',kernel_initializer='he_uniform',padding ='same'))\nmodel.add(MaxPooling2D((2,2)))\n\nmodel.add(Conv2D(64,(3,3),activation='relu',kernel_initializer='he_uniform',padding ='same'))\nmodel.add(MaxPooling2D((2,2)))\n\nmodel.add(Conv2D(64,(3,3),activation='relu',kernel_initializer='he_uniform',padding ='same'))\nmodel.add(MaxPooling2D((2,2)))\n\n\n\nmodel.add(Flatten())\nmodel.add(Dense(64,activation='relu',kernel_initializer='he_uniform'))\nmodel.add(Dense(128, activation = 'relu', kernel_initializer= 'he_uniform'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(10,activation='softmax'))\nmodel.summary()\n\nmodel.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\nhistory = model.fit(train_dataset,epochs=50,batch_size=128,validation_data=validation_dataset,verbose=1)","metadata":{"id":"6ycZdUjaSngP","outputId":"8ed31180-ca22-4fd9-ce6a-1a31be08c7c9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.utils import load_img\nfrom tensorflow.keras.utils import img_to_array\n\npath = '//content/gdrive/MyDrive/Exam/10 Fruits/Test'\nfor i in range (10):\n    img = load_img(path+'//'+str(i+1)+'.jpg',target_size=(150,150))\n    plt.imshow(img)\n    plt.show()\n\n    img = img_to_array(img)\n    img=np.reshape(img,(1,150,150,3))\n    img = img.astype('float32')\n    img = img/255\n    predict =  np.argmax(model.predict(img))\n    if predict==0:\n      print(\"Bưởi\")\n    elif predict==1: \n      print(\"Chôm chôm\")\n    elif predict==2: \n      print(\"chuối\")\n    elif predict==3: \n      print(\"Dâu tây \")\n    elif predict==4: \n      print(\"Dưa hấu \")\n    elif predict==5: \n      print(\"Khế \")\n    elif predict==6: \n      print(\"Nho \")\n    elif predict==7: \n      print(\"Quýt \")\n    elif predict==8: \n      print(\"Sầu riêng \")\n    elif predict==9: \n      print(\"Táo \")\n\nimg.shape","metadata":{"id":"yK6l3mxDTJzu","outputId":"4369096a-c2f0-47eb-c561-3cdd8becf8bd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset.class_indices","metadata":{"id":"jFBlGaZBcd4T","outputId":"38607982-6fd3-4636-9b74-8eb254cfe624"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\npd.DataFrame(history.history).plot(figsize=(8,5))\nplt.grid(True)\nplt.gca().set_ylim(0,6)\nplt.show()","metadata":{"id":"H1ayFFBhcebT","outputId":"37ac4dc0-4b3f-4ee1-8409-4965897ec37e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train','validation'],loc='upperleft')\nplt.show()","metadata":{"id":"UO7j1CFydzbq","outputId":"254d7fa0-a4c9-4e26-d414-65eac4f72dcb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"tWHc-Q-AVp2C"},"execution_count":null,"outputs":[]}]}